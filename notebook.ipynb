{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.4 64-bit ('base': conda)",
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5bb0378d4ee4c0aff941e0dc4c26640714a7475a262217eccf73e6de1579f1e3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_keys([&#39;room_Jan&#39;])"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = requests.get('https://b718b51c1217.ngrok.io/data/6ytwk4ivTB7QkmlL0QPA1HNQ7NCOAb6Y').json()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_df = pd.DataFrame(data['room_Jan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# During the analysis I didn't know which column represents sensors, and which represents devices. \n",
    "# That is why I have performed some data analysis to determine it. Also all sensors values have been \n",
    "# standarized, so that machine learning algorithms can converge easly to global minimum of \n",
    "# cost function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = deepcopy(real_data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "count                        36550\nunique                       36550\ntop       Fri Oct  2 23:01:20 2020\nfreq                             1\nName: date, dtype: object\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([&#39;Sun Sep 27 23:24:05 2020&#39;, &#39;Sun Sep 27 23:24:35 2020&#39;,\n       &#39;Sun Sep 27 23:24:55 2020&#39;, ..., &#39;Tue Oct  6 15:46:37 2020&#39;,\n       &#39;Tue Oct  6 15:46:58 2020&#39;, &#39;Tue Oct  6 15:47:18 2020&#39;],\n      dtype=object)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "print(real_data_df[columns[0]].describe())\n",
    "real_data_df[columns[0]].unique()\n",
    "# strings representing date, primary key of each table in the smarthouse project database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "count    36550.000000\nmean         0.204637\nstd          0.223791\nmin          0.000000\n25%          0.000000\n50%          0.140000\n75%          0.430000\nmax          0.800000\nName: sensor_light, dtype: float64\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.49, 0.23, 0.24, 0.52, 0.51, 0.48, 0.5 , 0.46, 0.45, 0.43, 0.4 ,\n       0.  , 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32, 0.33, 0.34,\n       0.35, 0.36, 0.37, 0.38, 0.39, 0.41, 0.42, 0.44, 0.47, 0.53, 0.54,\n       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n       0.22, 0.21, 0.2 , 0.19, 0.18, 0.17, 0.16, 0.15, 0.14, 0.13, 0.12,\n       0.11, 0.1 , 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01,\n       0.66, 0.67, 0.68, 0.75, 0.7 , 0.77, 0.8 , 0.79, 0.71, 0.69])"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "print(real_data_df[columns[1]].describe())\n",
    "real_data_df[columns[1]].unique()\n",
    "# values between 0.0 and 0.65, it is probably light sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "count     36550.0\nunique       67.0\ntop          21.7\nfreq       3112.0\nName: sensor_temperature, dtype: float64\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([21, 20.9, 21.1, 21.2, 21.3, 21.4, 21.5, 21.6, 21.7, &#39;nan&#39;, 20.8,\n       20.5, 20.2, 19.8, 19.6, 19.2, 19, 18.7, 18.5, 18.3, 18.1, 18, 17.8,\n       17.7, 17.6, 17.5, 17.4, 17.3, 17.2, 17.1, 17, 16.9, 16.8, 16.7,\n       16.6, 16.5, 16.4, 16.3, 16.2, 16.1, 17.9, 18.2, 18.4, 18.6, 18.8,\n       18.9, 19.1, 19.3, 19.4, 19.5, 19.7, 19.9, 20, 20.1, 20.3, 20.4,\n       20.6, 20.7, 21.8, 21.9, 22, 22.1, 22.2, 22.3, 22.4, 22.5, 22.6],\n      dtype=object)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "print(real_data_df[columns[2]].describe())\n",
    "real_data_df[columns[2]].unique()\n",
    "# real values between 0 and 22.1, also some 'nan' included, probably it is temperature sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "count    36550.000000\nmean         0.307360\nstd          0.461406\nmin          0.000000\n25%          0.000000\n50%          0.000000\n75%          1.000000\nmax          1.000000\nName: sensor_desktop, dtype: float64\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 1], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "print(real_data_df[columns[3]].describe())\n",
    "real_data_df[columns[3]].unique()\n",
    "# only zeros and ones, it is controllable divice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "count    36550.000000\nmean         0.515486\nstd          0.499767\nmin          0.000000\n25%          0.000000\n50%          1.000000\n75%          1.000000\nmax          1.000000\nName: device_blinds, dtype: float64\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 1], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "print(real_data_df[columns[4]].describe())\n",
    "real_data_df[columns[4]].unique()\n",
    "# only zeros and ones, it is controllable divice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "count    36550.000000\nmean         0.113735\nstd          0.317493\nmin          0.000000\n25%          0.000000\n50%          0.000000\n75%          0.000000\nmax          1.000000\nName: device_lamp, dtype: float64\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 0], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "print(real_data_df[columns[5]].describe())\n",
    "real_data_df[columns[5]].unique()\n",
    "# only zeros and ones, it is controllable divice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real_data_df.columns = ['date', 'sensor_1', 'sensor_2', 'device_1', 'device_2', 'device_3']\n",
    "real_data_df.index = real_data_df['date']\n",
    "real_data_df = real_data_df.drop(columns = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                          sensor_light sensor_temperature  sensor_desktop  \\\ndate                                                                        \nSun Sep 27 23:24:05 2020          0.49                 21               0   \nSun Sep 27 23:24:35 2020          0.23                 21               0   \nSun Sep 27 23:24:55 2020          0.23                 21               0   \nSun Sep 27 23:25:15 2020          0.24                 21               0   \nSun Sep 27 23:25:35 2020          0.23                 21               0   \n...                                ...                ...             ...   \nTue Oct  6 15:45:57 2020          0.42               22.4               1   \nTue Oct  6 15:46:17 2020          0.42               22.4               1   \nTue Oct  6 15:46:37 2020          0.42               22.4               1   \nTue Oct  6 15:46:58 2020          0.42               22.4               1   \nTue Oct  6 15:47:18 2020          0.42               22.3               1   \n\n                          device_blinds  device_lamp  \ndate                                                  \nSun Sep 27 23:24:05 2020              0            1  \nSun Sep 27 23:24:35 2020              0            1  \nSun Sep 27 23:24:55 2020              0            1  \nSun Sep 27 23:25:15 2020              0            1  \nSun Sep 27 23:25:35 2020              0            1  \n...                                 ...          ...  \nTue Oct  6 15:45:57 2020              1            1  \nTue Oct  6 15:46:17 2020              1            1  \nTue Oct  6 15:46:37 2020              1            1  \nTue Oct  6 15:46:58 2020              1            1  \nTue Oct  6 15:47:18 2020              1            1  \n\n[36550 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sensor_light</th>\n      <th>sensor_temperature</th>\n      <th>sensor_desktop</th>\n      <th>device_blinds</th>\n      <th>device_lamp</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Sun Sep 27 23:24:05 2020</td>\n      <td>0.49</td>\n      <td>21</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>Sun Sep 27 23:24:35 2020</td>\n      <td>0.23</td>\n      <td>21</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>Sun Sep 27 23:24:55 2020</td>\n      <td>0.23</td>\n      <td>21</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>Sun Sep 27 23:25:15 2020</td>\n      <td>0.24</td>\n      <td>21</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>Sun Sep 27 23:25:35 2020</td>\n      <td>0.23</td>\n      <td>21</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>Tue Oct  6 15:45:57 2020</td>\n      <td>0.42</td>\n      <td>22.4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>Tue Oct  6 15:46:17 2020</td>\n      <td>0.42</td>\n      <td>22.4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>Tue Oct  6 15:46:37 2020</td>\n      <td>0.42</td>\n      <td>22.4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>Tue Oct  6 15:46:58 2020</td>\n      <td>0.42</td>\n      <td>22.4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>Tue Oct  6 15:47:18 2020</td>\n      <td>0.42</td>\n      <td>22.3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>36550 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "real_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step is to determine best rule indiction algorithm. Our goal is to find a rule \n",
    "# of behaviours between devices and sensors, so that our algorithm can predict properly when it should\n",
    "# activate each device. 2 algorithms I am going to compare are Decision Trees, Random Forest and Extreeme Gradient Boosted Trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from copy import deepcopy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def f1_score(y_true, y_pred, threshold = 0.5):\n",
    "    y_pred_class = y_pred >= threshold\n",
    "    y_true = y_true == 1\n",
    "    return fbeta_score(y_true, y_pred_class, beta = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoTuningHyperparameters(object):\n",
    "    @staticmethod\n",
    "    def standarize(X, standarization_rule = None):\n",
    "        data = deepcopy(X.replace(['nan'], 0))\n",
    "        for column_name in data.columns:\n",
    "            if 'sensor' in column_name:\n",
    "                data[column_name] = (data[column_name] - data[column_name].mean())/data[column_name].std()\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_all_possible_params(params):\n",
    "        params_unpacked = {key: list(np.arange(params[key][0], params[key][1] + params[key][2], params[key][2])) for key in                     params.keys()}\n",
    "        keys, values = zip(*params_unpacked.items())\n",
    "        possible_params = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "        return possible_params\n",
    "\n",
    "    def __init__(self, model, X, y, params, cost):\n",
    "        self.model = model \n",
    "        X = self.standarize(X) \n",
    "        self.X_train = X[:int(0.7*len(X))]\n",
    "        self.X_test = X[int(0.7*len(X)):]\n",
    "        self.y_train = y[:int(0.7*len(y))]\n",
    "        self.y_test = y[int(0.7*len(y)):]\n",
    "        self.params = params\n",
    "        self.cost = cost\n",
    "        self.best_model = None\n",
    "    \n",
    "    def fit_model(self, params):\n",
    "        model = self.model(**params)\n",
    "        try:\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            predictions = model.predict(self.X_test)\n",
    "            return model, self.cost(self.y_test, predictions)\n",
    "        except:\n",
    "            return None, 0\n",
    "    \n",
    "    def grid_search(self, params = None, verbose = 1):\n",
    "        if params:\n",
    "            params = self.generate_all_possible_params(params)\n",
    "        else:\n",
    "            params = self.generate_all_possible_params(self.params)\n",
    "        models = []\n",
    "        for index, parameters in enumerate(params):\n",
    "            model, ratio = self.fit_model(parameters)\n",
    "            models.append([parameters, ratio])\n",
    "\n",
    "            if verbose >= 1:\n",
    "                print('{:.4f}'.format((index+1)/len(params)), end = '\\r')\n",
    "\n",
    "        sorted_models = [[x[0], x[1]] for x in sorted(models, key = lambda x: x[1])]\n",
    "        self.best_model = sorted_models[-1]\n",
    "        return self.best_model[0], self.best_model[1]\n",
    "\n",
    "    def random_search(self, verbose = 1, group_size = 5, iterations = 20, params = None):\n",
    "        if params:\n",
    "            params = self.generate_all_possible_params(params)\n",
    "        else:\n",
    "            params = self.generate_all_possible_params(self.params)\n",
    "\n",
    "        models = []\n",
    "        for iteration in range(iterations):\n",
    "            random_group = np.random.choice(params, group_size)\n",
    "            for random_params in random_group:\n",
    "                model, ratio = self.fit_model(random_params)\n",
    "                models.append([random_params, ratio])\n",
    "\n",
    "            if verbose >= 1:\n",
    "                print('{:.4f}'.format((iteration+1)/iterations), end = '\\r')\n",
    "\n",
    "        sorted_models = [[x[0], x[1]] for x in sorted(models, key = lambda x: x[1])]\n",
    "        self.best_model = sorted_models[-1]\n",
    "        return self.best_model[0], self.best_model[1]\n",
    "\n",
    "    def genetic_search(self):\n",
    "        pass \n",
    "\n",
    "    def auto_tune_pipeline(self, pipeline = ['random', 'grid'], narrow_to = 0.2, params = None):\n",
    "        if params:\n",
    "            params = params\n",
    "        else:\n",
    "            params = self.params\n",
    "        \n",
    "        possible_params_lengths = {key: len([param for param in np.arange(params[key][0], params[key][1], params[key][2])]) for key in list(params.keys())}\n",
    "\n",
    "        for search in pipeline:\n",
    "            if search == 'random':\n",
    "                best_params, score = self.random_search(params = params, group_size = 5, iterations = 50)\n",
    "            elif search == 'grid':\n",
    "                best_params, score = self.random_search(params = params)\n",
    "\n",
    "\n",
    "            for key in best_params.keys():\n",
    "                key_type = type(params[key][2])\n",
    "                params_length = possible_params_lengths[key]\n",
    "                new_min = key_type(best_params[key] - key_type(narrow_to * params_length) * params[key][2])\n",
    "                new_max = key_type(best_params[key] + key_type(narrow_to * params_length) * params[key][2])\n",
    "                if new_min > params[key][0]:\n",
    "                    params[key][0] = new_min\n",
    "                if new_max < params[key][1]:\n",
    "                    params[key][1] = new_max\n",
    "            print('new search ranges for parameters: {}'.format(params))\n",
    "\n",
    "            print('performed {} serach with max score of {} and best parameters {}'.format(search, score, best_params))\n",
    "\n",
    "        return best_params, score\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index([&#39;sensor_light&#39;, &#39;sensor_temperature&#39;, &#39;sensor_desktop&#39;, &#39;device_blinds&#39;,\n       &#39;device_lamp&#39;],\n      dtype=&#39;object&#39;)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "real_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_PARAMS = {'n_estimators ': [20, 300, 20], \n",
    "                'learning_rate': [0.01, 0.1, 0.01], \n",
    "                'max_depth': [3, 300, 30], \n",
    "                'subsample': [0.8, 1, 0.05], \n",
    "                'colsample_bytree': [0.3, 0.8, 0.05],\n",
    "                'gamma': [0, 5, 1],\n",
    "                'verbosity': [0, 0, 1]}\n",
    "\n",
    "X = deepcopy(real_data_df.drop(columns = ['device_blinds']))\n",
    "y = deepcopy(real_data_df['device_blinds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'n_estimators ': [1, 50, 1], \n",
    "#                 'learning_rate': [5, 15, 5], \n",
    "#                 'max_depth': [0.01, 0.1, 0.01]}\n",
    "# params_unpacked = {key: list(np.arange(params[key][0], params[key][1] + params[key][2], params[key][2])) for key in params.keys()}\n",
    "# params_unpacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "automl = AutoTuningHyperparameters(XGBClassifier, X, y, XGB_PARAMS, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automl pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "new search ranges for parameters: {&#39;n_estimators &#39;: [260, 300, 20], &#39;learning_rate&#39;: [0.022, 0.058, 0.01], &#39;max_depth&#39;: [153, 273, 30], &#39;subsample&#39;: [0.9600000000000002, 1, 0.05], &#39;colsample_bytree&#39;: [0.3999999999999999, 0.6, 0.05], &#39;gamma&#39;: [3, 5, 1], &#39;verbosity&#39;: [0, 0, 1]}\nperformed random serach with max score of 0.9059144676979072 and best parameters {&#39;n_estimators &#39;: 300, &#39;learning_rate&#39;: 0.04, &#39;max_depth&#39;: 213, &#39;subsample&#39;: 1.0000000000000002, &#39;colsample_bytree&#39;: 0.49999999999999994, &#39;gamma&#39;: 4, &#39;verbosity&#39;: 0}\nnew search ranges for parameters: {&#39;n_estimators &#39;: [260, 300, 20], &#39;learning_rate&#39;: [0.022, 0.05, 0.01], &#39;max_depth&#39;: [153, 213, 30], &#39;subsample&#39;: [0.9600000000000002, 1, 0.05], &#39;colsample_bytree&#39;: [0.3999999999999999, 0.5999999999999999, 0.05], &#39;gamma&#39;: [4, 5, 1], &#39;verbosity&#39;: [0, 0, 1]}\nperformed grid serach with max score of 0.8936013276784067 and best parameters {&#39;n_estimators &#39;: 300, &#39;learning_rate&#39;: 0.032, &#39;max_depth&#39;: 153, &#39;subsample&#39;: 0.9600000000000002, &#39;colsample_bytree&#39;: 0.4999999999999999, &#39;gamma&#39;: 5, &#39;verbosity&#39;: 0}\n"
    }
   ],
   "source": [
    "best_params, score = automl.auto_tune_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{&#39;n_estimators &#39;: 300,\n &#39;learning_rate&#39;: 0.032,\n &#39;max_depth&#39;: 153,\n &#39;subsample&#39;: 0.9600000000000002,\n &#39;colsample_bytree&#39;: 0.4999999999999999,\n &#39;gamma&#39;: 5,\n &#39;verbosity&#39;: 0}"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next thing that is needed for this project is data preprocessing module. During the analysis I had to analyse data only from one device. \n",
    "# Unfortunately, this is not the case in real life iot system. We can have lots of devices, sending data in not parallel time (ex. varying in one second). \n",
    "# Preprocessing module should be able to properly create array of data, with properly standarized features, and joined tables from dfferent devices. \n",
    "# Also, as the data is in form of time series, it should be properly batched and padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}